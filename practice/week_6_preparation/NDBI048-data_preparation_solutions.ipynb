{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0128ad0b",
   "metadata": {},
   "source": [
    "# Data preparation\n",
    "\n",
    "* From **business understanding**, we know the task to be solved.  \n",
    "* Then we do **data understanding** to look into data.\n",
    "* Now we are going to do some necessary or useful data transformation to reach the aim.\n",
    "\n",
    "## Outline\n",
    "0. Summary of data understanding\n",
    "1. Missing and invalid data\n",
    "2. Feature extraction\n",
    "3. Making different statistical units\n",
    "4. Data transformation\n",
    "\n",
    "## Data and tasks\n",
    "* Titanic2 (*titanic_train.csv*) - data preparation for an analysis of ticket fares\n",
    "* Home Credit (*application_train.csv*) - segmentation of clients by family situation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb31a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_theme(style=\"ticks\", color_codes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465ee695",
   "metadata": {},
   "source": [
    "## Part I. Titanic and ticket fares\n",
    "### Summary of data understanding\n",
    "Just few facts from the exploration -- for the aim of this practice.\n",
    "\n",
    "Let's consider these columns only: *pclass*, *sex*, *age*, *ticket*, *fare*, *cabin*, *embarked*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a75a9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data reading\n",
    "df1 = pd.read_csv('titanic_train.csv')\n",
    "df1 = df1[['passenger_id', 'ticket', 'pclass', 'fare', 'sex', 'age', 'cabin', 'embarked']]\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fa11a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# share of missing data (NaN, NULL) by columns\n",
    "print(1 - df1.count()/len(df1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1003360b",
   "metadata": {},
   "source": [
    "* *ticket*, *pclass* and *sex* are complete\n",
    "* *fare* and *embarked* have negligible counts of missing data\n",
    "* *age* and *cabin* have significant counts of missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a4f014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# invalid values in data?\n",
    "# frequency tables of categorical columns\n",
    "print(df1['pclass'].value_counts())\n",
    "print(df1['sex'].value_counts())\n",
    "print(df1['embarked'].value_counts())\n",
    "# the most often values in string columns\n",
    "print(df1['ticket'].value_counts().sort_values(ascending=False)[:5])\n",
    "print(df1['cabin'].value_counts().sort_values(ascending=False)[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965f233b",
   "metadata": {},
   "source": [
    "> String columns (*ticket*, *cabin*) have expected frequencies -- no value has too high frequency.  \n",
    "> Categorical columns seem to have valid values.\n",
    "\n",
    "Let's look into numeric columns (*age*, *fare*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb1a868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribution of values in numeric columns\n",
    "sns.displot(df1['fare'])\n",
    "print('Fare: minimum=', df1['fare'].min(), '; maximum=', df1['fare'].max(), '; median=', df1['fare'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbfffb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# zero fare is rather unexpected; how many passenger have zero fare?\n",
    "print('Passengers with zero fare: ', (df1['fare']==0).sum())\n",
    "print('The most often fares: ')\n",
    "print(df1['fare'].value_counts().sort_values(ascending=False).iloc[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8891a3e",
   "metadata": {},
   "source": [
    "> Fare values seem to be valid with exception of zero and missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96cdf2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(df1['age'])\n",
    "print('Age: minimum=', df1['age'].min(), '; maximum=', df1['age'].max(), '; median=', df1['age'].median())\n",
    "print('The most often ages:')\n",
    "print(df1['age'].value_counts().sort_values(ascending=False).iloc[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc6c1ce",
   "metadata": {},
   "source": [
    "> Age values seem to be fully valid with exception of missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b017c87c",
   "metadata": {},
   "source": [
    "### Dealing with missing and invalid data\n",
    "\n",
    "Now we use exploration outcomes for the data cleaning.\n",
    "\n",
    "**TASK 1.**  \n",
    "Consider how to treat missing or invalid data of fare, embarkment, age and cabin. Then prepare a script for data cleaning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be35bb4",
   "metadata": {},
   "source": [
    "**Answers:**\n",
    "\n",
    "* missing fare -- could be either omitted (one case only) or estimated from other attributes\n",
    "* zero fare -- few cases only, could be kept as valid (possibly special passengers) or omitted (possibly errors)\n",
    "* missing embarkment -- could be either be omitted (one case only) or estimated from other attributes\n",
    "* missing age -- should not be omitted (too many cases, we have to deal with it other way)\n",
    "* missing cabin -- should not be omitted (missing value is informative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e22961",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning - example of omitting records with missing values (keeping record with non-missing and valid values)\n",
    "# we will not run it yet\n",
    "# df1 = df1[df1['fare'].notna() & (df1['fare']>0) & (df1['embarked'].notna())]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4167d850",
   "metadata": {},
   "source": [
    "### Feature extraction\n",
    "\n",
    "Multiple persons travelled on one ticket, so they can have the same fare which was paid only once. It's a reason to make new statistical units &ndash; tickets. But is data for the same ticket consistent? Let's check the integrity of data for the tickets.\n",
    "\n",
    "**TASK 2.**  \n",
    "Explore whether all passengers with the same ticket have the same fare, pclass, embarkment and cabin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114f6b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# same fare for the same ticket?\n",
    "print(df1.groupby('ticket').agg({'fare': 'nunique'}).value_counts())\n",
    "# Which ticket is for a passenger with missing fare? Are there more passengers for this ticket?\n",
    "ticket_na_fare = df1[df1['fare'].isna()]['ticket'].values.tolist()\n",
    "df1[df1['ticket'].isin(ticket_na_fare)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88157b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# same pclass for the same ticket?\n",
    "print(df1.groupby('ticket').agg({'pclass': 'nunique'}).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915f0225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# same embarkments for the same ticket?\n",
    "print(df1.groupby('ticket').agg({'embarked': 'nunique'}).value_counts())\n",
    "# For which ticket were there more embarkments?\n",
    "tmp_tickets = df1.groupby('ticket').agg({'embarked': 'nunique'})\n",
    "ticket_mult_emb = tmp_tickets[tmp_tickets['embarked'] > 1].index.tolist()\n",
    "df1[df1['ticket'].isin(ticket_mult_emb)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1105dee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# same cabin for the same ticket?\n",
    "print(df1.groupby('ticket').agg({'cabin': 'nunique'}).value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb568332",
   "metadata": {},
   "source": [
    "> For each ticket, there is the same fare (possibly missing or zero) and same class.  \n",
    "> For each ticket except two cases, there is one embarkment place. One ticket has two places and one ticket none (missing).  \n",
    "> There can be various numbers of cabin for a ticket (and possibly none, too)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8caa76",
   "metadata": {},
   "source": [
    "Now we make a table of tickets by few steps:\n",
    "\n",
    "1. Base table -- unique rows of *ticket*, *pclass*, *fare* (we now there is integrity).\n",
    "2. Aggregated features grouped by *ticket* -- e. g. count of passengers; join aggregated table to the base table.\n",
    "3. Artificial aggregation as a solution of multiple embarkment -- we take the highest value of *embarked* to unify embarkment places for tickets.\n",
    "\n",
    "**TASK 3.**  \n",
    "Make a table with tickets as rows and features (some of them aggregated). Choose useful features for future analysis by yourself."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c628de",
   "metadata": {},
   "source": [
    "**Chosen features:**\n",
    "* count of passengers\n",
    "* ratio of male passengers\n",
    "* age of the youngest and of the oldest passenger\n",
    "* average age of passengers\n",
    "* count af passengers with known age\n",
    "* sex od the oldest passenger\n",
    "* count of (distinct) cabins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5433f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User function\n",
    "def rate_males(s):\n",
    "    return np.mean(np.where(s=='male', 1, 0))\n",
    "\n",
    "### Base table\n",
    "df2_base = df1[['ticket', 'pclass', 'fare']].drop_duplicates()\n",
    "df2_base = df2_base.set_index('ticket') # setting 'ticket' column as key\n",
    "\n",
    "### Multiple embarkment solution\n",
    "df2_emb = df1.groupby('ticket').agg({'embarked': 'max'})\n",
    "# print('Ticket with multiple embarkment has been unified:')\n",
    "# print(df2_emb.loc['113798'])\n",
    "# no need to set index - groupby + agg sets index by default\n",
    "\n",
    "### Some chosen features\n",
    "df2_feat = df1.groupby('ticket').agg({'ticket': 'count', 'sex': [rate_males],\n",
    "                                      'age': ['min', 'max', np.mean, 'count'], 'cabin': 'nunique'})\n",
    "# column names update\n",
    "df2_feat.columns = ['pass_cnt', 'rate_males', 'age_min', 'age_max', 'age_mean', 'age_valid_cnt', 'cabin_cnt']\n",
    "\n",
    "# sex of the oldest person for the ticket\n",
    "df2_feat_sex_oldest = df1.sort_values(by=['ticket', 'age'], ascending=[True, False]) \\\n",
    "    .drop_duplicates('ticket')[['ticket', 'sex']]\n",
    "df2_feat_sex_oldest = df2_feat_sex_oldest.set_index('ticket') # setting 'ticket' column as key\n",
    "df2_feat_sex_oldest.columns = ['sex_oldest']\n",
    "\n",
    "### Joining tables together\n",
    "df2 = df2_base.join(df2_emb) # join is by default LEFT and index<->index\n",
    "df2 = df2.join(df2_feat)\n",
    "df2 = df2.join(df2_feat_sex_oldest)\n",
    "\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87466f9c",
   "metadata": {},
   "source": [
    "### Data transformation\n",
    "\n",
    "* The distribution of fare is very skew. Let's transform it by log to get it better balanced.\n",
    "* The fare is given as a total. But it's better to get an average fare per one passenger.\n",
    "\n",
    "**TASK 4.**\n",
    "Add new columns to the table as stated above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b996b7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use log10 for better interpretation, but simple log is ok, too\n",
    "# be careful at zero fare - log is invalid! (we can use log(x+1) instead)\n",
    "df2['fare_log'] = np.log10(df2['fare']+1)\n",
    "df2['fare_per_pass'] = df2['fare'] / df2['pass_cnt']\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5995bcca",
   "metadata": {},
   "source": [
    "**TASK 5.**\n",
    "1. Make new columns as meaningful categories \"binned\" from count of passengers, mean age, count of distinct cabins.\n",
    "2. Make flags \"child\" and \"baby\": flag is True when the youngest passenger for a ticket was under 15, resp. under 3 years.\n",
    "3. Find the most often combinations of men and women travelling on one ticket (e. g. \"single man\", \"man+woman\", \"two men\", \"other\" etc.) and make a new column with category description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51452489",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, find proper breaks for binning; then make binning; then check frequencies\n",
    "\n",
    "### pass_cnt\n",
    "print(df2['pass_cnt'].value_counts())\n",
    "# categories will be 1, 2, 3, 4+\n",
    "df2['pass_cnt_cat'] = pd.cut(df2['pass_cnt'], [0, 1, 2, 3, 1000], labels=['1', '2', '3', '4+'])\n",
    "print(df2['pass_cnt_cat'].value_counts())\n",
    "\n",
    "### age_mean\n",
    "sns.displot(df2['age_mean'])\n",
    "# categories will be up to 15, 15-25, 25-40, 40+\n",
    "df2['age_mean_cat'] = pd.cut(df2['age_mean'], [0, 15, 20, 25, 30, 40, 1000],\n",
    "                             labels=['15-', '15-20', '20-25', '25-30', '30-40', '40+'])\n",
    "print(df2['age_mean_cat'].value_counts().sort_index())\n",
    "\n",
    "### cabin_cnt (same approach as pass_cnt)\n",
    "print(df2['cabin_cnt'].value_counts())\n",
    "# categories will be none, 1, 2+\n",
    "df2['cabin_cnt_cat'] = pd.cut(df2['cabin_cnt'], [0, 1, 2, 1000], right=False, labels=['none', '1', '2+'])\n",
    "print(df2['cabin_cnt_cat'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b092be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flags child and baby\n",
    "df2['flag_child'] = (df2['age_min'] < 15)\n",
    "df2['flag_baby'] = (df2['age_min'] < 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0267571b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze frequencies of various combinations\n",
    "pd.pivot_table(df2, values='fare', index=['pass_cnt_cat'], columns=['rate_males'], aggfunc=np.size)\n",
    "\n",
    "# then make a new column\n",
    "# very simple example - can be extended by nested np.where conditions\n",
    "df2['group'] = np.where((df2['rate_males']==1) & (df2['pass_cnt']==1), 'Single man', 'Other')\n",
    "\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530fcd07",
   "metadata": {},
   "source": [
    "## Part II. Home credit\n",
    "This dataset contains Home Credit clients who got a loan. Each client (=row in the dataset) has plenty of data in columns. We are interested in the segmentation of client portfolio. Segmentation is a division the basic dataset into some well-defined segment, like \"young single men\", \"old widow women living alone\" etc.\n",
    "\n",
    "The relevant columns are *days_birth*, *code_gender*, *cnt_children*, *cnt_fam_members*, *name_family_status*.\n",
    "\n",
    "**TASK: look into data and try to find some big segments based on some features from the set of relevant columns. You may need to do some binning before.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e91654",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hc = pd.read_csv('application_train.csv')\n",
    "df_hc.columns = df_hc.columns.str.lower()\n",
    "df_hc = df_hc[['days_birth', 'code_gender', 'cnt_children', 'cnt_fam_members', 'name_family_status']]\n",
    "df_hc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
