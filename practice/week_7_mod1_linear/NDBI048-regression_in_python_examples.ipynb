{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23c5302f",
   "metadata": {},
   "source": [
    "# Linear modelling in Python â€“ linear and logistic regression\n",
    "This notebook brings examples of basic linear modelling in Python on artificial data. Its aim is just to show approaches and code that can be use for fitting model, getting coefficients, evaluating its performance and predicting.\n",
    "\n",
    "## Contents\n",
    "1. [Useful links](#Useful-links)\n",
    "1. [Data](#Data)\n",
    "1. [Linear regression](#Linear-regression)\n",
    "1. [Logistic regression](#Logistic-regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b2a300",
   "metadata": {},
   "source": [
    "## Useful links\n",
    "* [Scikit LinearRegression class](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html)\n",
    "* [Scikit LogisticRegression class](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)\n",
    "* [Statsmodels linear regression](https://www.statsmodels.org/stable/regression.html)\n",
    "* [Statsmodels OLS method (ordinary least squares)](https://www.statsmodels.org/dev/generated/statsmodels.regression.linear_model.OLS.html)\n",
    "* [Statsmodels Logit method (logistic regression)](https://www.statsmodels.org/dev/generated/statsmodels.discrete.discrete_model.Logit.html)\n",
    "* [R style formulas in Statsmodels](https://www.statsmodels.org/stable/example_formulas.html)\n",
    "* [Statsmodels ols method (ordinary least squares with R formula)](https://www.statsmodels.org/stable/generated/statsmodels.formula.api.ols.html#statsmodels.formula.api.ols)\n",
    "* [Statsmodels logit method (logistic regression with R formula)](https://www.statsmodels.org/stable/generated/statsmodels.formula.api.logit.html)\n",
    "* [Scikit cross validation](https://scikit-learn.org/stable/modules/cross_validation.html)\n",
    "* [Metrics for model evaluation](https://scikit-learn.org/stable/modules/model_evaluation.html)\n",
    "* [Scikit one-hot encoding](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html)\n",
    "* [Pandas one-hot encoding](https://pandas.pydata.org/docs/reference/api/pandas.get_dummies.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8ec285",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "pd.set_option(\"display.precision\", 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0533a4a3",
   "metadata": {},
   "source": [
    "## Data\n",
    "This dataset is artificial. Data contains 16 rows and 5 columns: id, 2 binary columns (*approve* and *sex*) and 2 numeric columns (*age* and *salary*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a445521d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_art = pd.DataFrame(data={'id': range(16),\n",
    "                            'approve': [False, True, False, True, False, True, True, True, False, False, False,\n",
    "                                        True, True, False, True, False],\n",
    "                            'sex': np.concatenate((np.array(['M'] * 8), np.array(['F'] * 8))),\n",
    "                            'age': [20, 52, 33, 23, 44, 56, 39, 30, 42, 38, 50, 27, 46, 25, 35, 47],\n",
    "                            'salary': [20, 56, 37, 24, 47, 50, 41, 29, 45, 28, 43, 22, 45, 20, 28, 36]})\n",
    "df_art"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a80999",
   "metadata": {},
   "source": [
    "There are several packages for regression in Python. We deal with **sklearn** (scikit-learn) and **statsmodels**. Each of them has its pros and cons. **Sklearn** is machine-learning oriented, while **statsmodels** is better for explanatory and inferring purpose.\n",
    "\n",
    "> With each approach we do these steps:\n",
    "\n",
    "1. fitting a model\n",
    "2. getting coefficients of the model\n",
    "3. assessing significance of coeficients / possible dropping a predictor\n",
    "4. assessing model performance\n",
    "5. prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b38538",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de816193",
   "metadata": {},
   "source": [
    "## Linear regression\n",
    "In this part, we model *salary* (\"response\", \"target\") against *age* and *sex* (\"predictors\", \"explanatory\").\n",
    "\n",
    "* [Linear regression with one numeric predictor](#Linear-regression-with-one-numeric-predictor)\n",
    "* [Linear regression with one categorical predictor](#Linear-regression-with-one-categorical-predictor)\n",
    "* [Linear regression with multiple predictors](#Linear-regression-with-multiple-predictors)\n",
    "\n",
    "### Linear regression with one numeric predictor\n",
    "Let's take *salary* as response and *age* as predictor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973658e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chart\n",
    "g = sns.relplot(data=df_art, x=\"age\", y=\"salary\") \\\n",
    "    .set_axis_labels(\"Age [yrs]\", \"Salary [thousands of CZK]\") \\\n",
    "    .set(title=\"Salary by age\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d751914",
   "metadata": {},
   "source": [
    "#### A. Sklearn approach\n",
    "Use [LinearRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html) class with method `fit` to create model object.  \n",
    "Then use properties and methods of that object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54519fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_art[['age']]\n",
    "y = df_art['salary']\n",
    "# by default the intercept is included\n",
    "\n",
    "### fit model\n",
    "modelA = LinearRegression().fit(X, y)\n",
    "\n",
    "### get coefficients\n",
    "print('Intercept: ', modelA.intercept_)\n",
    "print('Beta coefficients: ', modelA.coef_)\n",
    "\n",
    "### assess coefficients / drop predictors\n",
    "# There is no straight way (like p-value). We can use performance metric and assess it;\n",
    "# then we can fit a submodel and compare performance metrics.\n",
    "\n",
    "### assess model performance\n",
    "# i. scoring itself directly (not recommended, overrates performance)\n",
    "print('R2 on itself: ', modelA.score(X, y))\n",
    "# ii. scoring by a cross-validation\n",
    "# https://scikit-learn.org/stable/modules/cross_validation.html\n",
    "scores = cross_val_score(LinearRegression(), X, y, cv=4)\n",
    "print('R2 by cval: ', scores)\n",
    "\n",
    "### predictions\n",
    "x_pred = 35 # prediction of salary for 35 yrs old\n",
    "print('Predicted salary for age=', x_pred, ' is ', modelA.predict([[x_pred]]))\n",
    "# predictions can be made on actual predictor values, too -> added to the chart"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d88017c",
   "metadata": {},
   "source": [
    "#### B. Statmodels classic\n",
    "Use [OLS method](https://www.statsmodels.org/stable/regression.html) to create model object.  \n",
    "Note that the model object is denoted as `res` there -- but we call it \"model\" to be consistent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b5c7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_int = sm.add_constant(X)\n",
    "# by default the intercept is NOT included - we need to add it\n",
    "\n",
    "### fit model\n",
    "modelB = sm.OLS(y, X_int).fit()\n",
    "\n",
    "### get coefficients\n",
    "print('Beta coefficients: ', modelB.params)\n",
    "\n",
    "### assess coefficients / drop predictors\n",
    "print(modelB.summary()) # detailed information of model and coefficients\n",
    "\n",
    "### assess model\n",
    "# i. scoring itself directly (not recommended, overrates performance)\n",
    "print('R2 on itself: ', modelB.rsquared)\n",
    "# ii. scoring by a cross-validation\n",
    "# cross-validation not available in this package, we can use approximation:\n",
    "print('R2 adjusted: ', modelB.rsquared_adj)\n",
    "\n",
    "### predictions\n",
    "x_pred = 35 # prediction of salary for 35 yrs old\n",
    "print('Predicted salary for age=', x_pred, ' is ', modelB.predict([1, x_pred]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d684d58f",
   "metadata": {},
   "source": [
    "#### C. Statsmodels with R formula notation\n",
    "In R language, the relation \"predictor <-> target\" can be written as formula:  \n",
    "*target* ~ *predictor1* + *predictor2* + ...\n",
    "\n",
    "[This possibility has been included](https://www.statsmodels.org/stable/example_formulas.html) into `statmodels` package. Use [ols method](https://www.statsmodels.org/stable/generated/statsmodels.formula.api.ols.html#statsmodels.formula.api.ols) from the `formula` submodule to create model object.\n",
    "\n",
    "Differences to B approach:\n",
    "* no need to add a column for the intercept\n",
    "* values for predictions are entered as a DataFrame\n",
    "\n",
    "Everything else is the same as for B approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "917420a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### fit model\n",
    "modelC = smf.ols(\"salary ~ age\", data=df_art).fit() # by default the intercept is included\n",
    "\n",
    "### get coefficients\n",
    "print('Beta coefficients: ', modelC.params)\n",
    "\n",
    "### assess coefficients / drop predictors\n",
    "print(modelC.summary()) # detailed information of model and coefficients\n",
    "\n",
    "### assess model\n",
    "# i. scoring itself directly (not recommended, overrates performance)\n",
    "print('R2 on itself: ', modelC.rsquared)\n",
    "# ii. scoring by a cross-validation\n",
    "# cross-validation not available in this package, we can use approximation:\n",
    "print('R2 adjusted: ', modelC.rsquared_adj)\n",
    "\n",
    "### predictions\n",
    "x_pred = 35 # prediction of salary for 35 yrs old\n",
    "y_pred = modelC.predict(pd.DataFrame({'age': x_pred}, index=range(1)))\n",
    "print('Predicted salary for age=', x_pred, ' is ', y_pred.values)\n",
    "# for prediction, data must be specified as DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4560f088",
   "metadata": {},
   "source": [
    "[Back to linear regression](#Linear-regression)\n",
    "\n",
    "----\n",
    "\n",
    "### Linear regression with one categorical predictor\n",
    "\n",
    "Let's take salary as response and sex as predictor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed13f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chart\n",
    "g = sns.catplot(data=df_art, x=\"sex\", y=\"salary\", kind=\"box\") \\\n",
    "    .set_axis_labels(\"Sex\", \"Salary [thousands of CZK]\") \\\n",
    "    .set(title=\"Salary by sex\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b32acf",
   "metadata": {},
   "source": [
    "Because both A and B approaches can deal with numeric model matrix only, we have to convert character (or generally categorical) column to one or many 0/1 columns. It is called [one-hot-encoding](https://www.educative.io/blog/one-hot-encoding). This can be reached by [sklearn.preprocessing.OneHotEncoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html) object or directly in pandas DataFrame by [get_dummies](https://pandas.pydata.org/docs/reference/api/pandas.get_dummies.html) function.\n",
    "\n",
    "The C approach does not need dummy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a16532",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preparation\n",
    "df_art['sex_orig'] = df_art['sex'] # backup of the original column - it will be lost!\n",
    "df_art = pd.get_dummies(df_art, columns=['sex'], drop_first=True)\n",
    "df_art.rename(columns = {'sex_orig':'sex'}, inplace = True) # renaming backuped column back\n",
    "df_art"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82df6692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# common for both A and B approaches\n",
    "X = df_art[['sex_M']]\n",
    "y = df_art['salary']\n",
    "\n",
    "# now fit and exploit the model as usually\n",
    "# A. sklearn\n",
    "modelA = LinearRegression().fit(X, y)\n",
    "# and everything is the same...\n",
    "print('Intercept: ', modelA.intercept_)\n",
    "print('Beta coefficients: ', modelA.coef_)\n",
    "print('R2 on itself: ', modelA.score(X, y))\n",
    "scores = cross_val_score(LinearRegression(), X, y, cv=4)\n",
    "print('R2 by cval: ', scores)\n",
    "# except prediction - it must use follow dummy (one-hot) encoding, i.e. \"male\" -> sex_M=1\n",
    "x_pred = 1\n",
    "print('Predicted salary for sex ', x_pred, ' is ', modelA.predict([[x_pred]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b93ce0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# B. statmodels\n",
    "# just use the dummy column (and add column of ones)\n",
    "X_int = sm.add_constant(X) # by default there is no intercept in model matrix X - we need to add it\n",
    "\n",
    "# now fit and exploit the model as usually\n",
    "modelB = sm.OLS(y, X_int).fit()\n",
    "print('Beta coefficients: ', modelB.params)\n",
    "print(modelB.summary()) # detailed information of model and coefficients\n",
    "print('R2 on itself: ', modelB.rsquared)\n",
    "print('R2 adjusted: ', modelB.rsquared_adj)\n",
    "x_pred = 1 # prediction of salary for a man, i. e. sex_M=1\n",
    "print('Predicted salary for sex=', x_pred, ' is ', modelB.predict([1, x_pred]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1799a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C. statmodels with R formula notation\n",
    "# no need to use dummy, just use R formula\n",
    "modelC = smf.ols(\"salary ~ sex\", data=df_art).fit()\n",
    "\n",
    "# and everything is the same as at the numeric predictor\n",
    "print('Beta coefficients: ', modelC.params)\n",
    "print(modelC.summary()) # detailed information of model and coefficients\n",
    "print('R2 on itself: ', modelC.rsquared)\n",
    "print('R2 adjusted: ', modelC.rsquared_adj)\n",
    "# for prediction, data must be specified as DataFrame\n",
    "x_pred = 'M' # and data must keep the original encoding\n",
    "y_pred = modelC.predict(pd.DataFrame({'sex': x_pred}, index=range(1)))\n",
    "print('Predicted salary for sex=', x_pred, ' is ', y_pred.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e405259",
   "metadata": {},
   "source": [
    "[Back to linear regression](#Linear-regression)\n",
    "\n",
    "----\n",
    "\n",
    "### Linear regression with multiple predictors\n",
    "Let's take two predictors now: *age* and *sex*.\n",
    "\n",
    "As we expect, it is necessary to use dummies for A and B approaches -- we use the matrix with two columns (*age*, *sex_M*) here. The C approach takes and preprocess columns just from the formula, so we need not make any preparation for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796daa0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_art[['age', 'sex_M']]\n",
    "y = df_art['salary']\n",
    "\n",
    "# A. sklearn\n",
    "modelA = LinearRegression().fit(X, y)\n",
    "print('Intercept: ', modelA.intercept_)\n",
    "print('Beta coefficients: ', modelA.coef_)\n",
    "x_pred = [35, 1]\n",
    "print('Predicted salary for age=', x_pred[0], 'and sex=', x_pred[1], ' is ', modelA.predict([x_pred]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e868c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# B. statmodels\n",
    "X_int = sm.add_constant(X)\n",
    "modelB = sm.OLS(y, X_int).fit()\n",
    "print(modelB.summary())\n",
    "print('Predicted salary for age=', x_pred[0], 'and sex=', x_pred[1], ' is ',\n",
    "      modelB.predict([1, x_pred[0], x_pred[1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb7879d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C. statmodels with R formula notation\n",
    "modelC = smf.ols(\"salary ~ age + sex\", data=df_art).fit()\n",
    "print(modelC.summary()) # detailed information of model and coefficients\n",
    "x_pred = [35, 'M'] # data must keep the original encoding\n",
    "y_pred = modelC.predict(pd.DataFrame({'age': x_pred[0], 'sex': x_pred[1]}, index=range(1)))\n",
    "print('Predicted salary for age=', x_pred[0], 'and sex=', x_pred[1], ' is ', y_pred.values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0c61ee",
   "metadata": {},
   "source": [
    "[Back to linear regression](#Linear-regression)\n",
    "\n",
    "----\n",
    "\n",
    "## Logistic regression\n",
    "In this part, we model approval (\"response\", \"target\") against age and sex (\"predictors\", \"explanatory\").\n",
    "\n",
    "* [Logistic regression with one numeric predictor](#Logistic-regression-with-one-numeric-predictor)\n",
    "* [Logistic regression with multiple predictors](#Logistic-regression-with-multiple-predictors)\n",
    "\n",
    "### Logistic regression with one numeric predictor\n",
    "Let's take approval as response and age as predictor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ebc970",
   "metadata": {},
   "source": [
    "#### A. Sklearn approach\n",
    "Use [LogisticRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) class with method `fit` to create model object.  \n",
    "Then use properties and methods of that object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64adda38",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_art[['age']]\n",
    "y = df_art['approve']\n",
    "# target can be True/False; by deafult the intercept is included\n",
    "### fit model\n",
    "modelA = LogisticRegression(solver='newton-cg', penalty='none').fit(X, y)\n",
    "\n",
    "### get coefficients\n",
    "print('Intercept: ', modelA.intercept_)\n",
    "print('Beta coefficients: ', modelA.coef_)\n",
    "\n",
    "### assess coefficients / drop predictors\n",
    "# Like LinearRegression, there is no straight way (like p-value). We can use performance metric and assess it;\n",
    "# then we can fit a submodel and compare performance metrics.\n",
    "\n",
    "### assess model performance\n",
    "# i. scoring itself directly (not recommended, overrates performance)\n",
    "# - score = accuracy\n",
    "print('Accuracy on itself: ', modelA.score(X, y))\n",
    "# ii. scoring by a cross-validation\n",
    "# https://scikit-learn.org/stable/modules/cross_validation.html\n",
    "# by default accuracy is used as a metric\n",
    "scores = cross_val_score(LogisticRegression(solver='newton-cg', penalty='none'), X, y, cv=4)\n",
    "print('Accuracy by cval: ', scores)\n",
    "# but we can change it, see https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
    "scores = cross_val_score(LogisticRegression(solver='newton-cg', penalty='none'), X, y, cv=4,\n",
    "                         scoring='roc_auc')\n",
    "print('ROC AUC by cval: ', scores)\n",
    "\n",
    "### predictions\n",
    "x_pred = 35 # prediction of approval for 35 yrs old\n",
    "print('Predicted approval for age=', x_pred, ' is ', modelA.predict([[x_pred]]))\n",
    "# if we want probability rather than strict classification, use method predict_proba\n",
    "# - it return probabilities of classes in the order False, True\n",
    "print('Predicted probability of approval for age=', x_pred, ' is ', modelA.predict_proba([[x_pred]])[0][1])\n",
    "# predictions can be made on actual predictor values, too -> for making the chart"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8ff9be",
   "metadata": {},
   "source": [
    "#### B. Statmodels classic\n",
    "Use [Logit method](https://www.statsmodels.org/dev/generated/statsmodels.discrete.discrete_model.Logit.html) to create model object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f872ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_int = sm.add_constant(X)\n",
    "# by default the intercept is NOT included - we need to add it\n",
    "# target can be True/False\n",
    "\n",
    "### fit model\n",
    "modelB = sm.Logit(y, X_int).fit(method='newton')\n",
    "### get coefficients\n",
    "print('Beta coefficients: ', modelB.params)\n",
    "\n",
    "### assess coefficients / drop predictors\n",
    "print(modelB.summary()) # detailed information of model and coefficients\n",
    "print(modelB.summary2()) # or slightly different output (contains AIC and BIC)\n",
    "# see https://www.statsmodels.org/stable/generated/statsmodels.discrete.discrete_model.LogitResults.html\n",
    "\n",
    "### assess model\n",
    "# i. scoring itself directly\n",
    "print('Pseudo R2: ', modelB.prsquared)\n",
    "# ii. scoring by a cross-validation\n",
    "# cross-validation not available in this package, we can use approximation:\n",
    "print('AIC on itself: ', modelB.aic)\n",
    "print('BIC on itself: ', modelB.bic)\n",
    "\n",
    "### predictions\n",
    "x_pred = 35 # prediction of approval for 35 yrs old\n",
    "print('Predicted probability of approval for age=', x_pred, ' is ', modelB.predict([1, x_pred]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b36aad",
   "metadata": {},
   "source": [
    "#### C. Statsmodels with R formula notation\n",
    "In R language, the relation \"predictor <-> target\" can be written as formula:  \n",
    "*target* ~ *predictor1* + *predictor2* + ...\n",
    "\n",
    "[This possibility has been included](https://www.statsmodels.org/stable/example_formulas.html?highlight=formula) into `statmodels` package. Use [logit method](https://www.statsmodels.org/stable/generated/statsmodels.formula.api.logit.html#statsmodels.formula.api.logit) from the `formula` submodule to create model object.\n",
    "\n",
    "Differences to B approach:\n",
    "* no need to add a column for the intercept\n",
    "* values for predictions are entered as a DataFrame\n",
    "\n",
    "Everything else is the same as for B approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c23e2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target MUST BE O/1, otherwise it would be converted to dummy columns\n",
    "df_art['approve_bin'] = df_art['approve'] * 1\n",
    "\n",
    "modelC = smf.logit(\"approve_bin ~ age\", data=df_art).fit() # by default the intercept is included\n",
    "# everything except prediction is the same as at B\n",
    "print('Beta coefficients: ', modelC.params)\n",
    "print(modelC.summary()) # detailed information of model and coefficients\n",
    "print('Pseudo R2: ', modelC.prsquared)\n",
    "print('AIC on itself: ', modelC.aic)\n",
    "print('BIC on itself: ', modelC.bic)\n",
    "\n",
    "# for prediction, data must be specified as DataFrame\n",
    "x_pred = 35 # prediction of approval for 35 yrs old\n",
    "y_pred = modelC.predict(pd.DataFrame({'age': x_pred}, index=range(1)))\n",
    "print('Predicted probability of approval for age=', x_pred, ' is ', y_pred.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a23edc",
   "metadata": {},
   "source": [
    "[Back to logistic regression](#Logistic-regression)\n",
    "\n",
    "----\n",
    "\n",
    "### Logistic regression with multiple predictors\n",
    "*Note: regression with one categorical predictor only is not mentioned here. It is similar to the linear regression (see the [corresponding section](#Linear-regression-with-one-categorical-predictor)) but uses objects and methods as any other logistic regression here.*\n",
    "\n",
    "Let's take two predictors now: *age* and *sex*.\n",
    "\n",
    "As we know from the linear regression, it is necessary to use dummies for A and B approaches -- we use the matrix with two columns (*age*, *sex_M*) here. The C approach takes and preprocess columns just from the formula, so we need not make any preparation for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5780b440",
   "metadata": {},
   "outputs": [],
   "source": [
    "# it's necessary to make dummies for A and B approaches (if they haven't existed yet)\n",
    "if (\"sex_M\" not in df_art.columns):\n",
    "    df_art['sex_orig'] = df_art['sex'] # backup of the original column - it will be lost!\n",
    "    df_art = pd.get_dummies(df_art, columns=['sex'], drop_first=True)\n",
    "    df_art.rename(columns = {'sex_orig':'sex'}, inplace = True) # renaming backuped column back\n",
    "\n",
    "X = df_art[['age', 'sex_M']]\n",
    "y = df_art['approve']\n",
    "\n",
    "# A. sklearn\n",
    "modelA = LogisticRegression(solver='newton-cg', penalty='none').fit(X, y)\n",
    "# and everything is the same as for one numeric predictor\n",
    "print('Intercept: ', modelA.intercept_)\n",
    "print('Beta coefficients: ', modelA.coef_)\n",
    "print('Accuracy on itself: ', modelA.score(X, y))\n",
    "scores = cross_val_score(LogisticRegression(solver='newton-cg', penalty='none'), X, y, cv=4)\n",
    "print('Accuracy by cval: ', scores)\n",
    "scores = cross_val_score(LogisticRegression(solver='newton-cg', penalty='none'), X, y, cv=4,\n",
    "                         scoring='roc_auc')\n",
    "print('ROC AUC by cval: ', scores)\n",
    "# except prediction - it must use follow dummy (one-hot) encoding, i.e. \"male\" -> sex_M=1\n",
    "x_pred = [35, 1]\n",
    "print('Predicted approval for age=', x_pred[0],\n",
    "      'and sex=', x_pred[1], ' is ', modelA.predict([x_pred]))\n",
    "print('Predicted probability of approval for age=', x_pred[0],\n",
    "      'and sex=', x_pred[1], ' is ', modelA.predict_proba([x_pred])[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea62d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# B. statsmodels classic\n",
    "X_int = sm.add_constant(X)\n",
    "\n",
    "modelB = sm.Logit(y, X_int).fit(method='newton')\n",
    "# and everything is the same as for one numeric predictor\n",
    "print('Beta coefficients: ', modelB.params)\n",
    "print(modelB.summary()) # detailed information of model and coefficients\n",
    "print(modelB.summary2()) # or slightly different output (contains AIC and BIC)\n",
    "print('Pseudo R2: ', modelB.prsquared)\n",
    "print('AIC on itself: ', modelB.aic)\n",
    "print('BIC on itself: ', modelB.bic)\n",
    "# prediction follows dummy (one-hot) encoding, i.e. \"male\" -> sex_M=1\n",
    "x_pred = [35, 1]\n",
    "print('Predicted probability of approval for age=', x_pred[0], 'and sex=', x_pred[1], ' is ',\n",
    "      modelB.predict([1, x_pred[0], x_pred[1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63cf371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C. statsmodels with R formula notation\n",
    "df_art['approve_bin'] = df_art['approve'] * 1 # again, target must be 0/1, not True/False\n",
    "\n",
    "modelC = smf.logit(\"approve_bin ~ age + sex\", data=df_art).fit()\n",
    "# and everything except prediction is the same as at B\n",
    "print('Beta coefficients: ', modelC.params)\n",
    "print(modelC.summary()) # detailed information of model and coefficients\n",
    "print('Pseudo R2: ', modelB.prsquared)\n",
    "print('AIC on itself: ', modelC.aic)\n",
    "print('BIC on itself: ', modelC.bic)\n",
    "# for prediction, data must be specified as DataFrame and keep the original encoding\n",
    "x_pred = [35, 'M']\n",
    "y_pred = modelC.predict(pd.DataFrame({'age': x_pred[0], 'sex': x_pred[1]}, index=range(1)))\n",
    "print('Predicted probability of approval for age=', x_pred[0], 'and sex=', x_pred[1], ' is ', y_pred.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf39c17e",
   "metadata": {},
   "source": [
    "[Back to logistic regression](#Logistic-regression)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
