{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0533a4a3",
   "metadata": {},
   "source": [
    "# MLOps\n",
    "\n",
    "This notebook contains an example of fitting and evaluating linear regression model on Titanic data. We will use tickets as modelling units (rows, entities), *fare* as target (possibly log fare) and various features as predictors.\n",
    "\n",
    "## Data\n",
    "\n",
    "We use the dataset Titanic and data preparation from the recent practice (see Data Preparation)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b24c8a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Tasks\n",
    "\n",
    "1. Add tracking for following items into experiment named `dev-titanic`:\n",
    "   - Log a regression model\n",
    "   - Log performance metrics\n",
    "   - Log names of used features (name the parameter \"schema\")\n",
    "   - Log model's class name (name the parameter \"model_class\")\n",
    "   - Then in another runs:\n",
    "     - Log summary of statsmodels' OLS model (as text)\n",
    "     - Log image `self_description.png`\n",
    "2. Collect **same** metrics from various regression models into experiment named `titanic`\n",
    "   - Keep same logging strategy (keep the lines starting with `mlflow.` almost the same), just change the model\n",
    "   - Use different hyperparameters for different regressors\n",
    "     - Log the hyperparameters to mlflow\n",
    "3. OPTIONAL: Compare models using MLFlow\n",
    "   - Find the best performing model using \"visual metrics comparison\"\n",
    "   - Find the best performing model using barplots.\n",
    "4. OPTIONAL: send some screenshots of some (preferably last) task to `samuel.fabo@profinit.eu`\n",
    "   - Totally not mandatory, but your guide will be glad and would like to see that you learned something useful :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f8ec285",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import mlflow\n",
    "\n",
    "pd.set_option(\"display.precision\", 2)\n",
    "plt.rcParams['figure.figsize'] = [8, 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8c7abc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Titanic data reading and preparing - reminder from `Data Preparation` practice\n",
    "df_t1 = pd.read_csv('titanic_train.csv') # adjust file path\n",
    "df_t1 = df_t1[['passenger_id', 'ticket', 'pclass', 'fare', 'sex', 'age', 'cabin', 'embarked']]\n",
    "\n",
    "# cleaning\n",
    "df_t1 = df_t1[df_t1['fare'].notna() & (df_t1['fare']>0) & (df_t1['embarked'].notna())]\n",
    "\n",
    "# making new dataset of tickets\n",
    "# User function\n",
    "def rate_males(s):\n",
    "    return np.mean(np.where(s=='male', 1, 0))\n",
    "\n",
    "### Base table\n",
    "df_t2_base = df_t1[['ticket', 'pclass', 'fare']].drop_duplicates()\n",
    "df_t2_base = df_t2_base.set_index('ticket') # setting 'ticket' column as key\n",
    "\n",
    "### Multiple embarkment solution\n",
    "df_t2_emb = df_t1.groupby('ticket').agg({'embarked': 'max'})\n",
    "# no need to set index - groupby + agg sets index by default\n",
    "\n",
    "### Some chosen features\n",
    "df_t2_feat = df_t1.groupby('ticket').agg({'ticket': 'count', 'sex': [rate_males],\n",
    "                                      'age': ['min', 'max', np.mean, 'count'], 'cabin': 'nunique'})\n",
    "# column names update\n",
    "df_t2_feat.columns = ['pass_cnt', 'rate_males', 'age_min', 'age_max', 'age_mean', 'age_valid_cnt', 'cabin_cnt']\n",
    "\n",
    "# sex of the oldest person for the ticket\n",
    "df_t2_feat_sex_oldest = df_t1.sort_values(by=['ticket', 'age'], ascending=[True, False]) \\\n",
    "    .drop_duplicates('ticket')[['ticket', 'sex']]\n",
    "df_t2_feat_sex_oldest = df_t2_feat_sex_oldest.set_index('ticket') # setting 'ticket' column as key\n",
    "df_t2_feat_sex_oldest.columns = ['sex_oldest']\n",
    "\n",
    "### Joining tables together\n",
    "df_t2 = df_t2_base.join(df_t2_emb) # join is by default LEFT and index<->index\n",
    "df_t2 = df_t2.join(df_t2_feat)\n",
    "df_t2 = df_t2.join(df_t2_feat_sex_oldest)\n",
    "\n",
    "# mathematical transformations\n",
    "df_t2['fare_log'] = np.log10(df_t2['fare']) # we use log10 for better interpretation, but simple log is ok, too.\n",
    "df_t2['fare_per_pass'] = df_t2['fare'] / df_t2['pass_cnt']\n",
    "\n",
    "# binning, making categories and flags\n",
    "### pass_cnt\n",
    "df_t2['pass_cnt_cat'] = pd.cut(df_t2['pass_cnt'], [0, 1, 2, 3, 1000], labels=['1', '2', '3', '4+'])\n",
    "\n",
    "### age_mean\n",
    "df_t2['age_mean_cat'] = pd.cut(df_t2['age_mean'], [0, 15, 20, 25, 30, 40, 1000],\n",
    "                             labels=['15-', '15-20', '20-25', '25-30', '30-40', '40+'])\n",
    "\n",
    "### cabin_cnt (same approach as pass_cnt)\n",
    "df_t2['cabin_cnt_cat'] = pd.cut(df_t2['cabin_cnt'], [0, 1, 2, 1000], right=False, labels=['none', '1', '2+'])\n",
    "\n",
    "# flags\n",
    "df_t2['flag_child'] = (df_t2['age_min'] < 15)\n",
    "df_t2['flag_baby'] = (df_t2['age_min'] < 3)\n",
    "\n",
    "### cleanup\n",
    "del df_t2_base\n",
    "del df_t2_emb\n",
    "del df_t2_feat\n",
    "del df_t2_feat_sex_oldest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62820c88",
   "metadata": {},
   "source": [
    "## Linear regression\n",
    "\n",
    "We learned that *fare* is very skew, we have transformed it by log10. So we take *fare_log* as target and *embarked*, *pclass* and *pass_cnt* as predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4687854",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept:  1.7463160900361796\n",
      "Beta coefficients:  [ 0.17662938 -0.33836997]\n"
     ]
    }
   ],
   "source": [
    "X = df_t2[['pass_cnt', 'pclass']]\n",
    "y = df_t2['fare_log']\n",
    "\n",
    "# fit model\n",
    "modelA = LinearRegression().fit(X, y)\n",
    "\n",
    "# get coefficients\n",
    "print('Intercept: ', modelA.intercept_)\n",
    "print('Beta coefficients: ', modelA.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45470ee4",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 by cval:  [0.81738928 0.8683794  0.77887764 0.82084394]\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(LinearRegression(), X, y, cv=4)\n",
    "print('R2 by cval: ', scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f70f9f1",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:               fare_log   R-squared:                       0.839\n",
      "Model:                            OLS   Adj. R-squared:                  0.838\n",
      "Method:                 Least Squares   F-statistic:                     1680.\n",
      "Date:                Wed, 07 Dec 2022   Prob (F-statistic):          6.63e-257\n",
      "Time:                        11:31:27   Log-Likelihood:                 344.40\n",
      "No. Observations:                 650   AIC:                            -682.8\n",
      "Df Residuals:                     647   BIC:                            -669.4\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      1.7463      0.021     83.030      0.000       1.705       1.788\n",
      "pass_cnt       0.1766      0.007     25.719      0.000       0.163       0.190\n",
      "pclass        -0.3384      0.007    -47.738      0.000      -0.352      -0.324\n",
      "==============================================================================\n",
      "Omnibus:                      164.742   Durbin-Watson:                   2.072\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              650.045\n",
      "Skew:                           1.121   Prob(JB):                    6.99e-142\n",
      "Kurtosis:                       7.357   Cond. No.                         11.9\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "ridgeModel = smf.ols(\"fare_log ~ pass_cnt + pclass\", data=df_t2).fit()\n",
    "ols_summary = ridgeModel.summary()\n",
    "print(ols_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad45d9bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: MLFLOW_TRACKING_URI=http://127.0.0.1:5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:C:\\\\Users\\\\vojta\\\\UK\\\\22-23_W\\\\data-science\\\\NDBI048-data-science\\\\practice\\\\week_9_mlops\\\\analysis/mlruns/1', creation_time=1670407081422, experiment_id='1', last_update_time=1670407081422, lifecycle_stage='active', name='my-experiment', tags={}>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%set_env MLFLOW_TRACKING_URI=http://127.0.0.1:5000\n",
    "mlflow.set_experiment(\"my-experiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b8a782f-e596-4863-b261-663b15478a02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vojta\\UK\\22-23_W\\data-science\\NDBI048-data-science\\practice\\week_9_mlops\\.venv\\lib\\site-packages\\_distutils_hack\\__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run() as run:\n",
    "    modelA = LinearRegression().fit(X,y)\n",
    "    mlflow.sklearn.log_model(modelA, \"model\")\n",
    "    \n",
    "    scores = cross_val_score(LinearRegression(), X, y, cv=4)\n",
    "    mlflow.log_metric(\"r2_score\", np.mean(scores))\n",
    "    mlflow.log_param(\"schema\", list(X.columns))\n",
    "    mlflow.log_param(\"model_class\", type(modelA))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b485a359-144f-43ca-84ae-9ce894db4960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:               fare_log   R-squared:                       0.839\n",
      "Model:                            OLS   Adj. R-squared:                  0.838\n",
      "Method:                 Least Squares   F-statistic:                     1680.\n",
      "Date:                Wed, 07 Dec 2022   Prob (F-statistic):          6.63e-257\n",
      "Time:                        11:31:30   Log-Likelihood:                 344.40\n",
      "No. Observations:                 650   AIC:                            -682.8\n",
      "Df Residuals:                     647   BIC:                            -669.4\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      1.7463      0.021     83.030      0.000       1.705       1.788\n",
      "pass_cnt       0.1766      0.007     25.719      0.000       0.163       0.190\n",
      "pclass        -0.3384      0.007    -47.738      0.000      -0.352      -0.324\n",
      "==============================================================================\n",
      "Omnibus:                      164.742   Durbin-Watson:                   2.072\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              650.045\n",
      "Skew:                           1.121   Prob(JB):                    6.99e-142\n",
      "Kurtosis:                       7.357   Cond. No.                         11.9\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run() as run:\n",
    "    modelB = smf.ols(\"fare_log ~ pass_cnt + pclass\", data=df_t2).fit()\n",
    "    ols_summary = modelB.summary()\n",
    "    print(ols_summary)\n",
    "    mlflow.log_text(str(ols_summary), \"ols_summary.txt\") # detailed information of model and coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "79192183-0eec-4959-909a-c527f7cb3c8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/12/07 11:32:19 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n"
     ]
    },
    {
     "ename": "RepresenterError",
     "evalue": "('cannot represent an object', Ridge())",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRepresenterError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m alpha \u001b[39m=\u001b[39m \u001b[39m1.0\u001b[39m\n\u001b[0;32m      3\u001b[0m ridgeModel \u001b[39m=\u001b[39m Ridge(alpha\u001b[39m=\u001b[39malpha)\u001b[39m.\u001b[39mfit(X,y)\n\u001b[1;32m----> 4\u001b[0m mlflow\u001b[39m.\u001b[39;49msklearn\u001b[39m.\u001b[39;49mlog_model(\u001b[39m\"\u001b[39;49m\u001b[39mridge\u001b[39;49m\u001b[39m\"\u001b[39;49m, ridgeModel)\n\u001b[0;32m      6\u001b[0m scores \u001b[39m=\u001b[39m cross_val_score(ridgeModel, X, y, cv\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m)\n\u001b[0;32m      7\u001b[0m mlflow\u001b[39m.\u001b[39mlog_metric(\u001b[39m\"\u001b[39m\u001b[39mr2_score\u001b[39m\u001b[39m\"\u001b[39m, np\u001b[39m.\u001b[39mmean(scores))\n",
      "File \u001b[1;32mc:\\Users\\vojta\\UK\\22-23_W\\data-science\\NDBI048-data-science\\practice\\week_9_mlops\\.venv\\lib\\site-packages\\mlflow\\sklearn\\__init__.py:407\u001b[0m, in \u001b[0;36mlog_model\u001b[1;34m(sk_model, artifact_path, conda_env, code_paths, serialization_format, registered_model_name, signature, input_example, await_registration_for, pip_requirements, extra_pip_requirements, pyfunc_predict_fn)\u001b[0m\n\u001b[0;32m    320\u001b[0m \u001b[39m@format_docstring\u001b[39m(LOG_MODEL_PARAM_DOCS\u001b[39m.\u001b[39mformat(package_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mscikit-learn\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[0;32m    321\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlog_model\u001b[39m(\n\u001b[0;32m    322\u001b[0m     sk_model,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    333\u001b[0m     pyfunc_predict_fn\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpredict\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    334\u001b[0m ):\n\u001b[0;32m    335\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    336\u001b[0m \u001b[39m    Log a scikit-learn model as an MLflow artifact for the current run. Produces an MLflow Model\u001b[39;00m\n\u001b[0;32m    337\u001b[0m \u001b[39m    containing the following flavors:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    405\u001b[0m \u001b[39m        mlflow.sklearn.log_model(sk_model, \"sk_models\")\u001b[39;00m\n\u001b[0;32m    406\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 407\u001b[0m     \u001b[39mreturn\u001b[39;00m Model\u001b[39m.\u001b[39;49mlog(\n\u001b[0;32m    408\u001b[0m         artifact_path\u001b[39m=\u001b[39;49martifact_path,\n\u001b[0;32m    409\u001b[0m         flavor\u001b[39m=\u001b[39;49mmlflow\u001b[39m.\u001b[39;49msklearn,\n\u001b[0;32m    410\u001b[0m         sk_model\u001b[39m=\u001b[39;49msk_model,\n\u001b[0;32m    411\u001b[0m         conda_env\u001b[39m=\u001b[39;49mconda_env,\n\u001b[0;32m    412\u001b[0m         code_paths\u001b[39m=\u001b[39;49mcode_paths,\n\u001b[0;32m    413\u001b[0m         serialization_format\u001b[39m=\u001b[39;49mserialization_format,\n\u001b[0;32m    414\u001b[0m         registered_model_name\u001b[39m=\u001b[39;49mregistered_model_name,\n\u001b[0;32m    415\u001b[0m         signature\u001b[39m=\u001b[39;49msignature,\n\u001b[0;32m    416\u001b[0m         input_example\u001b[39m=\u001b[39;49minput_example,\n\u001b[0;32m    417\u001b[0m         await_registration_for\u001b[39m=\u001b[39;49mawait_registration_for,\n\u001b[0;32m    418\u001b[0m         pip_requirements\u001b[39m=\u001b[39;49mpip_requirements,\n\u001b[0;32m    419\u001b[0m         extra_pip_requirements\u001b[39m=\u001b[39;49mextra_pip_requirements,\n\u001b[0;32m    420\u001b[0m         pyfunc_predict_fn\u001b[39m=\u001b[39;49mpyfunc_predict_fn,\n\u001b[0;32m    421\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\vojta\\UK\\22-23_W\\data-science\\NDBI048-data-science\\practice\\week_9_mlops\\.venv\\lib\\site-packages\\mlflow\\models\\model.py:373\u001b[0m, in \u001b[0;36mModel.log\u001b[1;34m(cls, artifact_path, flavor, registered_model_name, await_registration_for, **kwargs)\u001b[0m\n\u001b[0;32m    371\u001b[0m run_id \u001b[39m=\u001b[39m mlflow\u001b[39m.\u001b[39mtracking\u001b[39m.\u001b[39mfluent\u001b[39m.\u001b[39m_get_or_start_run()\u001b[39m.\u001b[39minfo\u001b[39m.\u001b[39mrun_id\n\u001b[0;32m    372\u001b[0m mlflow_model \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m(artifact_path\u001b[39m=\u001b[39martifact_path, run_id\u001b[39m=\u001b[39mrun_id)\n\u001b[1;32m--> 373\u001b[0m flavor\u001b[39m.\u001b[39msave_model(path\u001b[39m=\u001b[39mlocal_path, mlflow_model\u001b[39m=\u001b[39mmlflow_model, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    374\u001b[0m mlflow\u001b[39m.\u001b[39mtracking\u001b[39m.\u001b[39mfluent\u001b[39m.\u001b[39mlog_artifacts(local_path, mlflow_model\u001b[39m.\u001b[39martifact_path)\n\u001b[0;32m    375\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\vojta\\UK\\22-23_W\\data-science\\NDBI048-data-science\\practice\\week_9_mlops\\.venv\\lib\\site-packages\\mlflow\\sklearn\\__init__.py:283\u001b[0m, in \u001b[0;36msave_model\u001b[1;34m(sk_model, path, conda_env, code_paths, mlflow_model, serialization_format, signature, input_example, pip_requirements, extra_pip_requirements, pyfunc_predict_fn)\u001b[0m\n\u001b[0;32m    272\u001b[0m     _logger\u001b[39m.\u001b[39mwarning(\n\u001b[0;32m    273\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mModel was missing function: \u001b[39m\u001b[39m{\u001b[39;00mpyfunc_predict_fn\u001b[39m}\u001b[39;00m\u001b[39m. Not logging python_function flavor!\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    274\u001b[0m     )\n\u001b[0;32m    276\u001b[0m mlflow_model\u001b[39m.\u001b[39madd_flavor(\n\u001b[0;32m    277\u001b[0m     FLAVOR_NAME,\n\u001b[0;32m    278\u001b[0m     pickled_model\u001b[39m=\u001b[39mmodel_data_subpath,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    281\u001b[0m     code\u001b[39m=\u001b[39mcode_path_subdir,\n\u001b[0;32m    282\u001b[0m )\n\u001b[1;32m--> 283\u001b[0m mlflow_model\u001b[39m.\u001b[39;49msave(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(path, MLMODEL_FILE_NAME))\n\u001b[0;32m    285\u001b[0m \u001b[39mif\u001b[39;00m conda_env \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    286\u001b[0m     \u001b[39mif\u001b[39;00m pip_requirements \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\vojta\\UK\\22-23_W\\data-science\\NDBI048-data-science\\practice\\week_9_mlops\\.venv\\lib\\site-packages\\mlflow\\models\\model.py:294\u001b[0m, in \u001b[0;36mModel.save\u001b[1;34m(self, path)\u001b[0m\n\u001b[0;32m    292\u001b[0m \u001b[39m\"\"\"Write the model as a local YAML file.\"\"\"\u001b[39;00m\n\u001b[0;32m    293\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(path, \u001b[39m\"\u001b[39m\u001b[39mw\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m out:\n\u001b[1;32m--> 294\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mto_yaml(out)\n",
      "File \u001b[1;32mc:\\Users\\vojta\\UK\\22-23_W\\data-science\\NDBI048-data-science\\practice\\week_9_mlops\\.venv\\lib\\site-packages\\mlflow\\models\\model.py:282\u001b[0m, in \u001b[0;36mModel.to_yaml\u001b[1;34m(self, stream)\u001b[0m\n\u001b[0;32m    280\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mto_yaml\u001b[39m(\u001b[39mself\u001b[39m, stream\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    281\u001b[0m     \u001b[39m\"\"\"Write the model as yaml string.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 282\u001b[0m     \u001b[39mreturn\u001b[39;00m yaml\u001b[39m.\u001b[39;49msafe_dump(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mto_dict(), stream\u001b[39m=\u001b[39;49mstream, default_flow_style\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "File \u001b[1;32mc:\\Users\\vojta\\UK\\22-23_W\\data-science\\NDBI048-data-science\\practice\\week_9_mlops\\.venv\\lib\\site-packages\\yaml\\__init__.py:269\u001b[0m, in \u001b[0;36msafe_dump\u001b[1;34m(data, stream, **kwds)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msafe_dump\u001b[39m(data, stream\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds):\n\u001b[0;32m    264\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[39m    Serialize a Python object into a YAML stream.\u001b[39;00m\n\u001b[0;32m    266\u001b[0m \u001b[39m    Produce only basic YAML tags.\u001b[39;00m\n\u001b[0;32m    267\u001b[0m \u001b[39m    If stream is None, return the produced string instead.\u001b[39;00m\n\u001b[0;32m    268\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 269\u001b[0m     \u001b[39mreturn\u001b[39;00m dump_all([data], stream, Dumper\u001b[39m=\u001b[39mSafeDumper, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n",
      "File \u001b[1;32mc:\\Users\\vojta\\UK\\22-23_W\\data-science\\NDBI048-data-science\\practice\\week_9_mlops\\.venv\\lib\\site-packages\\yaml\\__init__.py:241\u001b[0m, in \u001b[0;36mdump_all\u001b[1;34m(documents, stream, Dumper, default_style, default_flow_style, canonical, indent, width, allow_unicode, line_break, encoding, explicit_start, explicit_end, version, tags, sort_keys)\u001b[0m\n\u001b[0;32m    239\u001b[0m     dumper\u001b[39m.\u001b[39mopen()\n\u001b[0;32m    240\u001b[0m     \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m documents:\n\u001b[1;32m--> 241\u001b[0m         dumper\u001b[39m.\u001b[39;49mrepresent(data)\n\u001b[0;32m    242\u001b[0m     dumper\u001b[39m.\u001b[39mclose()\n\u001b[0;32m    243\u001b[0m \u001b[39mfinally\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\vojta\\UK\\22-23_W\\data-science\\NDBI048-data-science\\practice\\week_9_mlops\\.venv\\lib\\site-packages\\yaml\\representer.py:27\u001b[0m, in \u001b[0;36mBaseRepresenter.represent\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrepresent\u001b[39m(\u001b[39mself\u001b[39m, data):\n\u001b[1;32m---> 27\u001b[0m     node \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrepresent_data(data)\n\u001b[0;32m     28\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mserialize(node)\n\u001b[0;32m     29\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrepresented_objects \u001b[39m=\u001b[39m {}\n",
      "File \u001b[1;32mc:\\Users\\vojta\\UK\\22-23_W\\data-science\\NDBI048-data-science\\practice\\week_9_mlops\\.venv\\lib\\site-packages\\yaml\\representer.py:48\u001b[0m, in \u001b[0;36mBaseRepresenter.represent_data\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m     46\u001b[0m data_types \u001b[39m=\u001b[39m \u001b[39mtype\u001b[39m(data)\u001b[39m.\u001b[39m\u001b[39m__mro__\u001b[39m\n\u001b[0;32m     47\u001b[0m \u001b[39mif\u001b[39;00m data_types[\u001b[39m0\u001b[39m] \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39myaml_representers:\n\u001b[1;32m---> 48\u001b[0m     node \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49myaml_representers[data_types[\u001b[39m0\u001b[39;49m]](\u001b[39mself\u001b[39;49m, data)\n\u001b[0;32m     49\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     50\u001b[0m     \u001b[39mfor\u001b[39;00m data_type \u001b[39min\u001b[39;00m data_types:\n",
      "File \u001b[1;32mc:\\Users\\vojta\\UK\\22-23_W\\data-science\\NDBI048-data-science\\practice\\week_9_mlops\\.venv\\lib\\site-packages\\yaml\\representer.py:207\u001b[0m, in \u001b[0;36mSafeRepresenter.represent_dict\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrepresent_dict\u001b[39m(\u001b[39mself\u001b[39m, data):\n\u001b[1;32m--> 207\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrepresent_mapping(\u001b[39m'\u001b[39;49m\u001b[39mtag:yaml.org,2002:map\u001b[39;49m\u001b[39m'\u001b[39;49m, data)\n",
      "File \u001b[1;32mc:\\Users\\vojta\\UK\\22-23_W\\data-science\\NDBI048-data-science\\practice\\week_9_mlops\\.venv\\lib\\site-packages\\yaml\\representer.py:118\u001b[0m, in \u001b[0;36mBaseRepresenter.represent_mapping\u001b[1;34m(self, tag, mapping, flow_style)\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[39mfor\u001b[39;00m item_key, item_value \u001b[39min\u001b[39;00m mapping:\n\u001b[0;32m    117\u001b[0m     node_key \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrepresent_data(item_key)\n\u001b[1;32m--> 118\u001b[0m     node_value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrepresent_data(item_value)\n\u001b[0;32m    119\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39misinstance\u001b[39m(node_key, ScalarNode) \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m node_key\u001b[39m.\u001b[39mstyle):\n\u001b[0;32m    120\u001b[0m         best_style \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\vojta\\UK\\22-23_W\\data-science\\NDBI048-data-science\\practice\\week_9_mlops\\.venv\\lib\\site-packages\\yaml\\representer.py:58\u001b[0m, in \u001b[0;36mBaseRepresenter.represent_data\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m     56\u001b[0m     node \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39myaml_multi_representers[\u001b[39mNone\u001b[39;00m](\u001b[39mself\u001b[39m, data)\n\u001b[0;32m     57\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39myaml_representers:\n\u001b[1;32m---> 58\u001b[0m     node \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49myaml_representers[\u001b[39mNone\u001b[39;49;00m](\u001b[39mself\u001b[39;49m, data)\n\u001b[0;32m     59\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     60\u001b[0m     node \u001b[39m=\u001b[39m ScalarNode(\u001b[39mNone\u001b[39;00m, \u001b[39mstr\u001b[39m(data))\n",
      "File \u001b[1;32mc:\\Users\\vojta\\UK\\22-23_W\\data-science\\NDBI048-data-science\\practice\\week_9_mlops\\.venv\\lib\\site-packages\\yaml\\representer.py:231\u001b[0m, in \u001b[0;36mSafeRepresenter.represent_undefined\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    230\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrepresent_undefined\u001b[39m(\u001b[39mself\u001b[39m, data):\n\u001b[1;32m--> 231\u001b[0m     \u001b[39mraise\u001b[39;00m RepresenterError(\u001b[39m\"\u001b[39m\u001b[39mcannot represent an object\u001b[39m\u001b[39m\"\u001b[39m, data)\n",
      "\u001b[1;31mRepresenterError\u001b[0m: ('cannot represent an object', Ridge())"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run() as run:\n",
    "    alpha = 1.0\n",
    "    ridgeModel = Ridge(alpha=alpha).fit(X,y)\n",
    "    mlflow.sklearn.log_model(\"ridge\", ridgeModel)\n",
    "    \n",
    "    scores = cross_val_score(ridgeModel, X, y, cv=3)\n",
    "    mlflow.log_metric(\"r2_score\", np.mean(scores))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "86e53d0f7483faf63c34058aa1ed1719806f488d53f906942d85be7bd8bb6566"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
